{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1N58kqahuQdUaJtM513z7uBmUQABe2xKM","authorship_tag":"ABX9TyOd9AaT/qHnh1VPd2kIkkuR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Adding utility functions "],"metadata":{"id":"yb1LWbmu3b0n"}},{"cell_type":"code","source":["# data: https://download.pytorch.org/tutorial/data.zip\n","import io\n","import os\n","import unicodedata\n","import string\n","import glob\n","import torch\n","import random\n","\n","os.chdir('/content/drive/MyDrive/Data Science WorkSpace/PyTorch tutorials/RNN/names')\n","\n","# alphabet small + capital letters + \" .,;'\"\n","ALL_LETTERS = string.ascii_letters + \" .,;'\"\n","N_LETTERS = len(ALL_LETTERS)\n","\n","# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n","def unicode_to_ascii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","        and c in ALL_LETTERS\n","    )\n","\n","def load_data():\n","    # Build the category_lines dictionary, a list of names per language\n","    category_lines = {}\n","    all_categories = []\n","    \n","    def find_files(path):\n","        return glob.glob(path)\n","    \n","    # Read a file and split into lines\n","    def read_lines(filename):\n","        lines = io.open(filename, encoding='utf-8').read().strip().split('\\n')\n","        return [unicode_to_ascii(line) for line in lines]\n","    \n","    for filename in find_files('*.txt'):\n","        category = os.path.splitext(os.path.basename(filename))[0]\n","        all_categories.append(category)\n","        \n","        lines = read_lines(filename)\n","        category_lines[category] = lines\n","        \n","    return category_lines, all_categories\n","\n","\"\"\"\n","To represent a single letter, we use a “one-hot vector” of \n","size <1 x n_letters>. A one-hot vector is filled with 0s\n","except for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>.\n","To make a word we join a bunch of those into a\n","2D matrix <line_length x 1 x n_letters>.\n","That extra 1 dimension is because PyTorch assumes\n","everything is in batches - we’re just using a batch size of 1 here.\n","\"\"\"\n","\n","# Find letter index from all_letters, e.g. \"a\" = 0\n","def letter_to_index(letter):\n","    return ALL_LETTERS.find(letter)\n","\n","# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n","def letter_to_tensor(letter):\n","    tensor = torch.zeros(1, N_LETTERS)\n","    tensor[0][letter_to_index(letter)] = 1\n","    return tensor\n","\n","# Turn a line into a <line_length x 1 x n_letters>,\n","# or an array of one-hot letter vectors\n","def line_to_tensor(line):\n","    tensor = torch.zeros(len(line), 1, N_LETTERS)\n","    for i, letter in enumerate(line):\n","        tensor[i][0][letter_to_index(letter)] = 1\n","    return tensor\n","\n","def random_training_example(category_lines, all_categories):\n","    \n","    def random_choice(a):\n","        random_idx = random.randint(0, len(a) - 1)\n","        return a[random_idx]\n","    \n","    category = random_choice(all_categories)\n","    line = random_choice(category_lines[category])\n","    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n","    line_tensor = line_to_tensor(line)\n","    return category, line, category_tensor, line_tensor\n","\n","if __name__ == '__main__':\n","    print(ALL_LETTERS)\n","    print(unicode_to_ascii('Ślusàrski'))\n","    \n","    category_lines, all_categories = load_data()\n","    print(category_lines['Italian'][:5])\n","    \n","    print(letter_to_tensor('J')) # [1, 57]\n","    print(line_to_tensor('Jones').size()) # [5, 1, 57]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kptutWmkTwhi","executionInfo":{"status":"ok","timestamp":1665160747901,"user_tz":-330,"elapsed":4803,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"40d6585c-4781-45f5-e7f1-0f30e10068fa"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\n","Slusarski\n","['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0.]])\n","torch.Size([5, 1, 57])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Qj6wfYMuA6pX"},"execution_count":null,"outputs":[]}]}